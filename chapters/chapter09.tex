\newpage
\chapter{Статистическа обработка на данните}
\label{chapter09}
\thispagestyle{empty}

Статистическата обработка на данни се състои основно от два вида статистика – описателна статистика\index{описателна статистика} и сравнителна статистика\index{сравнителна статистика}. При описателната статистика се изчисляват определени параметри описващи характеристики на събраните данни, докато при сравнителната статистика се извършва сравнение между някои от описателните параметри на данните. 

\section{Описателна статистика}

Параметрите при описателната статистика основно са свързани с някакво централно групиране на данните и някакво разпръскване (дисперсия) около централното групиране. Параметри за централно групиране са средната стойност, медианата и модата, а параметри за разпръскване са дисперсията и стандартното отклонение.

\begin{lstlisting}[caption=Генериране на извадка от случайни числа, label=listing0160]
v1 <- round( rnorm(100, mean=62, sd=72) )

v2 <- v1

v2[sample(x=1:100, size=15, replace=FALSE)] <- NA

w1 <- 1 / sample(x=1:100, size=100, replace=TRUE)
\end{lstlisting}

За да бъдат илюстрирани възможностите на R за пресмятане на описателни статистики се използва извадка от 100 нормално разпределени случайни числа (Листинг \ref{listing0160}). Често в реалната практика данните съдържат липсващи измервания. При такава ситуация трябва да се вземат допълнителни мерки за пресмятане на описателните статистики. Функцията $sample$ в R позволява на случаен принцип част от стойностите в определен вектор да бъдат избрани на случаен принцип, при равномерно вероятностно разпределение. Тази възможност се използва за замяна на 15\% от генерираните данни с липсваща стойност (Листинг \ref{listing0160}). Параметърът replace указва дали определено число може да бъде избрано повторно или не.

\subsection{Средна стойност}

Средната стойност\index{средна} е най-често използваната статистика и представлява сумата от стойностите разделена на общия брой стойности (Листинг. \ref{listing0161}).

\begin{lstlisting}[caption=Средна стойност, label=listing0161]
sum(v1) / length(v1)

mean( v1 )

mean( v2 )

mean(v2, na.rm=TRUE)
\end{lstlisting}

Когато липсват стойности при проведените измервания е невъзможно да се изчисли средната стойност без да се вземе решение как да се обработят липсващите числа. Има различни подходи за обработката на липсите, като интерполация или премахване. Независимо кой подход бъде избран, то той неизбежно води до внасяне на допълнителна грешка при пресмятанията. Ако бъде извършена интерполация\index{интерполация}, то съседните измервания биха внесли грешка в липсващите стойности. Ако бъдат премахнати липсващите измервания, то размерът на извадката намалява, а от там се увеличава и неточността на последващите пресмятания. 

В някои ситуации отделните измерени стойности имат различна тежест и се налага те да участват с различен коефициент при пресмятането на средната стойност\index{претеглена средна} (Листинг \ref{listing0162}). Такава е ситуацията когато се пресмята бал за прием в учебно заведение. Различните компоненти формиращи бал на всеки кандидат участват с различна тежест.

\begin{lstlisting}[caption=Претеглена средна стойност, label=listing0162]
weighted.mean(x=v1, w=w1)
\end{lstlisting}

\subsection{Минимална стойност, максимална стойност, медиана и мода}

В практиката често от значение е диапазонът в който се разпростират данните. В програмния пакет R този диапазон лесно се установява с функциите min и max (Листинг \ref{listing0163}).

\begin{lstlisting}[caption={Минимум, максимум, медиана и мода}, label=listing0163]
min( v1 )

max( v1 )

median( v1 )

# Mode calculation.
unique(v1)[ which.max( tabulate(match(v1,unique(v1)) ) ) ]
\end{lstlisting}

Един от основните недостатъци на средната стойност е, че при наличието на екстремално различни отделни измервания силно могат да повлияят върху общото пресмятане на средната стойност. Поради тази причина в практиката много често се използва медианата\index{медиана}, а не средната стойност (Листинг \ref{listing0163}). За да се пресметне медианата данните се сортират. При нечетен брой стойности медианата е стойността на средния елемент. При четен брой стойности медианата е средно аритметично между двата елемента в средата. 

Модата\index{мода} е параметър, който отразява най-често срещаната стойност в множеството от данни. Освен числена стойност модата може да има и символна стойност, според характера на самите данни. В програмния пакет R няма функция, която да изчислява модата, но тя лесно може да се пресметне с комбинация от извикването на други функции (Листинг \ref{listing0163}).

\subsection{Дисперсия и стандартно отклонение}

След като бъде установено някакво централно групиране в данните е от съществено значение по какъв начин данните са разпръснати около това централно групиране. Изчисляването на дисперсията\index{дисперсия} спомага за изследване на разпръскването (Листинг \ref{listing0164}). Дисперсията се изчислява като сума от квадрата на разликите между всяка стойност и средната, разделена на броя стойности минус едно. 

\begin{lstlisting}[caption=Дисперсия и стандартно отклонение, label=listing0164]
sum( (v1-mean(v1))^2 ) / (length(v1) - 1)

var( v1 )

sqrt( var(v1) )

sd( v1 )
\end{lstlisting}

Основен недостатък на дисперсията е, че се изчислява с повдигане на втора степен и полученият резултат е несравним с оригиналните измервания. Примерно при серия измервания в метри резултатът от изчислението на дисперсията би имал смисъла на квадратни метри. За да бъдат сравними стойностите е достатъчно дисперсията да се подложи на корен квадратен, което коригира резултата получен с повдигане на втора степен. Резултатът от квадратния корен на дисперсията се нарича стандартно отклонение\index{стандартно отклонение} (Листинг \ref{listing0164}).

\subsection{Квантили и обобщение}

Квантилите\index{квантили} определят каква част от измерените стойности попадат в определен процент от вероятностното разпределение (Листинг \ref{listing0164}).

\begin{lstlisting}[caption=Квантили и обобщение, label=listing0165]
quantile(v1, probs=c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9))
#  10%   20%   30%   40%   50%   60%   70%   80%   90% 
#-28.0  -0.4  19.0  41.6  66.5  84.4 110.6 121.8 150.2 

summary( v1 )
\end{lstlisting}

Програмният пакет R предоставя и обобщаваща функция за описателните статистики наречена $summary$ и тя визуализира стойностите за минимална, максимална, медиана, средна, първи и трети квантил.

\section{Сравнителна статистика}

Когато се работи с две или повече случайни променливи от ползва идва апарата на сравнителната статистика\index{сравнителна статистика}. Целта е да се изследва връзката между тези променливи. За променливи от едно и също измерване най-често се използват корелацията и ковариацията, а за сравнение на средни T-тест и ANOVA. 

\subsection{Ковариация и корелация}

Корелационният\index{корелация} коефициент е число в интервала -1 до +1 и показва възможността за наличие на взаимна връзка между две случайни променливи. Важно е да се отбележи, че корелационният коефициент не гарантира наличие на взаимна връзка, а само указва, че такава връзка е възможна. 

\begin{lstlisting}[caption=Ковариация и корелация, label=listing0166]
library(ggplot2)

cor(economics$psavert, economics$pce)

# Correlation formula.
sum((economics$psavert-mean(economics$psavert)) * (economics$pce-mean(economics$pce))) / ((nrow(economics)-1) * sd(economics$psavert) * sd(economics$pce))

cor(economics[, c("pce","psavert","uempmed","unemploy")])

cov(economics$psavert, economics$pce)

cov(economics[, c("pce","psavert","uempmed","unemploy")])

# Correlation is a covariance divided by the standard deviation.
identical(cov(economics$psavert,economics$pce),cor(economics$psavert,economics$pce)*sd(economics$psavert)*sd(economics$pce))
\end{lstlisting}

В пакета ggplot2 множеството от данни $economics$ дава идеална възможност да се демонстрира концепцията за корелация и ковариация (Листинг \ref{listing0166}). Колоната $psavert$ отразява индивидуалното спестовно ниво, а колоната $pce$ индивидуалните разходи. При относително еднакво ниво на доходите, чисто интуитивно е ясно, че който харчи повече би следвало да спестява по-малко. Това ще рече, че когато едната стойност нараства другата стойност ще намалява и това има смисъла на отрицателна корелационна връзка. В демонстрирания пример корелационният коефициент е -0.7928546 и отразява точно факта за възможно наличие на относително силна отрицателна корелационна връзка. 

\begin{equation}
r_{xy} = \frac{\sum_{i=1}^{n}(x_i-\bar{x})(y_i-\bar{y})}{(n-1)s_xs_y}
\label{equation0009}
\end{equation}
\listofequations{Корелационен коефициент}

Корелационният коефициент се пресмята като сума от разликите между множителите на отделните измервания в разлика от средната стойност, разделена на умножението между стандартните отклонения на двете променливи с броя измервания минус единица (Формула \ref{equation0009}). При стойност близка до +1 е възможна силна положителна корелационна връзка, при стойност близка до -1 е възможна силна отрицателна корелационна връзка, а при стойност близка до 0 наличието на корелационна връзка е много малко вероятно. 

Когато корелацията се смята между повече от две случайни променливи резултатът е корелационна матрица (Листинг \ref{listing0166}). При корелационната матрица\index{корелационна матрица} е показана възможната връзка между всяка двойка променливи. 

\begin{equation}
v_{xy} = \frac{1}{n-1}\sum_{i=1}^{n}(x_i-\bar{x})(y_i-\bar{y})
\label{equation0010}
\end{equation}
\listofequations{Ковариационен коефициент}

Ковариацията\index{ковариация} е подобна на корелацията, като разликата е, че стойностите не са нормирани (Формула \ref{equation0010}). Може да се приеме като аналогия между дисперсията и стандартното отклонение (Листинг \ref{listing0166}). Ковариацията може да бъде голямо отрицателно число или голяма положително число. В посочения пример ковариацията е със стойност -8359.069, при съответната ковариационна матрица. 

Както при описателните статистики, при ковариацията и корелацията липси в измерванията възпрепятстват изчисляването на крайните стойности. 

\subsection{Тест на Стюдънт}

От сравнителната статистика t-теста\index{t-тест} (или тест на Стюдънт) е един от най-разпространените подходи за сравнение на средните стойности между две извадки. 

\begin{lstlisting}[caption=Тестово множество за бакшиши, label=listing0167]
library(reshape2)

head(tips)

#   total_bill  tip    sex smoker day   time size
# 1      16.99 1.01 Female     No Sun Dinner    2
# 2      10.34 1.66   Male     No Sun Dinner    3
# 3      21.01 3.50   Male     No Sun Dinner    3
# 4      23.68 3.31   Male     No Sun Dinner    2
# 5      24.59 3.61 Female     No Sun Dinner    4
# 6      25.29 4.71   Male     No Sun Dinner    4
\end{lstlisting}

За илюстриране на възможностите, които R предлага при пресмятането на $t$-теста е подходящо да се използва множеството данни за бакшиши (Листинг \ref{listing0167}).

\subsubsection{Тест на една извадка}

При тестването на една извадка\index{тест на една извадка} теста се прилага за определяне на средната стойности и съответният доверителен интервал. От съществено значение е данните да са нормално разпределение което означава, че имат конкретна средна стойност и конкретно стандартно отклонение. Ако тестваната стойност попада в доверителния интервал, то може да се заключи, че това е действителната средна стойност. В противен случай не може да се приеме, че предположената средна стойност е действителната средна стойност. 

\begin{lstlisting}[caption=Тест на единична извадка, label=listing0168]
t.test(tips$tip, alternative="two.sided", mu=3.50)

# 	One Sample t-test
# 
# data:  tips$tip
# t = -5.6642, df = 243, p-value = 4.161e-08
# alternative hypothesis: true mean is not equal to 3.5
# 95 percent confidence interval:
#  2.823799 3.172758
# sample estimates:
# mean of x 
#  2.998279 
\end{lstlisting}

При проверката дали средната стойност на бакшишите е \$3.5 $t$-тестът завършва с отчет за пресметнатите стойности (Листинг \ref{listing0168}), което включва - $t$ статистиката, степените на свобода и $p$ стойността\index{p-стойност}. Също така е представена информация за 95 процентният доверителен интервал и информация за средната стойност на изследваната променлива. Постигнатата $p$ стойност означава, че нулевата хипотеза трябва да бъде отхвърлена. Това води до заключението, че средната стойност на бакшишите не може да е \$3.5. Нулевата хипотеза\index{нулева хипотеза} е това, което се смята за истина (в примера това е средна стойност е равна на \$3.5). 

\begin{equation}
t = \frac{\bar{x}-\mu_0}{s_{\bar{x}}/\sqrt{n}}
\label{equation0011}
\end{equation}
\listofequations{T-статистика}

T-статистиката се смята по формула \ref{equation0011} и има смисъла на отношение между разликата от пресметнатото средно ($\bar{x}$) и предположеното средно ($\mu_0$), а като делител е стандартната грешка на пресметнатото средно ($s_{\bar{x}}/\sqrt{n}$). В уравнението $s_{\bar{x}}$ има смисъла на стандартно отклонение, а $n$ е броят на наблюденията. 

\begin{figure}[h!]
  \centering
  \includegraphics[width=1.0\linewidth]{pic0056}
  \caption{Т-статистика за бакшиши}
\label{figure0056}
\end{figure}
\FloatBarrier

Когато предположената средна стойност е вярна очакването е $t$-статистиката да попада в интервала от две стандартни отклонения, около средната стойност (Фиг. \ref{figure0056}). 

\begin{lstlisting}[caption=Визуализация на t-разпределение, label=listing0169]
library( ggplot2 )

# Generation of t-distributed random values.
values <- rt(10000, df = NROW( tips ) - 1)

# T-statistics calculation.
t <- t.test(tips$tip, alternative="two.sided", mu=3.50)

# Visualization.
ggplot(data.frame(x=values)) + geom_density(aes(x=x), fill="grey", color="grey") + geom_vline(xintercept=t$statistic) + geom_vline(xintercept=mean(values) + c(-2, 2) * sd(values), linetype=2)
\end{lstlisting}

Изисква определено усилие за правилно интерпретиране на $p$-стойността. По своята същност тази стойност отразява вероятността нулевата хипотеза да е вярна. На практика измерва колко екстремна е измерената статистика (в този случай средната стойност). Ако статистиката е твърде екстремна трябва да се направи заключение, че нулевата хипотеза трябва да бъде отхвърлена. Основното усложнение с $p$-стойността е как да се определи кое ниво трябва да се възприеме като твърде екстремно. В практиката (емпирично) са наложени следните стойности за екстремност на $p$-стойността - 0.10, 0.05 и 0.01. Поради емпиричния характер за определяне на тези стойност по настояще възникват въпроси до колко те са адекватни, спрямо съвременните тенденции в обработката на статистически данни. 

Степените на свобода\index{степени на свобода} са втората сложна за възприемане концепция. По своята същност степените на свобода отразяват броя ефективни наблюдения в конкретен експеримент. Общата концепция за степените на свобода е броят на наблюденията минус броя параметри, които трябва да се определят. В случая на $t$-разпределението само един параметър трябва да се определи (стандартната грешка). В демонстрирания пример (Листинг \ref{listing0169}) има 244 наблюдения и съответно 244-1 = 243 степени на свобода. 

\begin{lstlisting}[caption=Едностранна t-статистика, label=listing0170]
t.test(tips$tip, alternative="less", mu=3.50)

# 	One Sample t-test
# 
# data:  tips$tip
# t = -5.6642, df = 243, p-value = 2.08e-08
# alternative hypothesis: true mean is less than 3.5
# 95 percent confidence interval:
#      -Inf 3.144535
# sample estimates:
# mean of x 
#  2.998279 
\end{lstlisting}

Нулевата хипотеза\index{нулева хипотеза} може да се анализира спрямо двете страни на вероятностното разпределение или да се разглежда само една от страните (по-малко или по-голямо). В този случай (Листинг \ref{listing0170}) $p$-стойността показва, че не можем да отхвърлим нулевата хипотеза. 

\subsubsection{Тест на две извадки}

Тестът на Стюдънт много по-често се прилага върху две извадки\index{тест на две извадки}. В тестовото множество от данни за бакшишите отделните измервания могат да се разделят по различни признаци в две групи (примерно бакшиши на мъжете и бакшиши на жените Фиг. \ref{figure0057}).

\begin{lstlisting}[caption=Сравнение на две извадки, label=listing0171]
ggplot(tips, aes(x=tip, fill=sex)) + geom_histogram(binwidth=1.0, alpha=0.8)

# Compute the variance for the two groups.
aggregate(tip ~ sex, data=tips, var)

# Test for normality.
shapiro.test(tips$tip[tips$sex == "Female"])
shapiro.test(tips$tip[tips$sex == "Male"])
shapiro.test( tips$tip )

# 	Shapiro-Wilk normality test
# 
# data:  tips$tip
# W = 0.89781, p-value = 8.2e-12

# Examine the equality of variances.
ansari.test(tip ~ sex, tips)

# 	Ansari-Bradley test
# 
# data:  tip by sex
# AB = 5582.5, p-value = 0.376
# alternative hypothesis: true ratio of scales is not equal to 1

t.test(tip~sex, data=tips, var.equal=TRUE)

# 	Two Sample t-test
# 
# data:  tip by sex
# t = -1.3879, df = 242, p-value = 0.1665
# alternative hypothesis: true difference in means is not equal to 0
# 95 percent confidence interval:
#  -0.6197558  0.1074167
# sample estimates:
# mean in group Female   mean in group Male 
#             2.833448             3.089618

library(plyr)

# Checking of the means in two standard deviations range.
ddply(tips, "sex", summarize, tip.mean=mean(tip), tip.sd=sd(tip), Lower=tip.mean-2*tip.sd/sqrt(NROW(tip)), Upper=tip.mean+2*tip.sd/sqrt(NROW(tip))) 

#      sex tip.mean   tip.sd    Lower    Upper
# 1 Female 2.833448 1.159495 2.584827 3.082070
# 2   Male 3.089618 1.489102 2.851931 3.327304

ggplot(ddply(tips, "sex", summarize, tip.mean=mean(tip), tip.sd=sd(tip), Lower=tip.mean-2*tip.sd/sqrt(NROW(tip)), Upper=tip.mean+2*tip.sd/sqrt(NROW(tip))), aes(x=tip.mean, y=sex)) + geom_point() + geom_errorbarh(aes(xmin=Lower, xmax=Upper), height=.2)
\end{lstlisting}

За да бъде надежден традиционният $t$-тест от съществено значение е дисперсията на двете извадки да бъде идентична. В ситуации където дисперсиите не са идентични се използва $t$-тест на Welch за две извадки. 

\begin{figure}[h!]
  \centering
  \includegraphics[width=1.0\linewidth]{pic0057}
  \caption{Разпределение на бакшишите според пола на сервитьора}
\label{figure0057}
\end{figure}
\FloatBarrier

На Фиг. \ref{figure0057} и при теста на Shapiro-Wilk (Листинг \ref{listing0171}) ясно се вижда, че двете извадки не са нормално разпределени. Тъй като данните очевидно не са нормално разпределени за проверката на идентичността на дисперсиите се прилага тест на Ansari-Bradley. Резултатът показва, че дисперсиите са достатъчно сходни и може да се приложи $t$-тест. От получения резултат (Листинг \ref{listing0171}) не може да се заключи, че нивото на бакшишите между мъжете и жените се различава достатъчно съществено. 

\subsubsection{Сдвоен тест на две извадки}

В някои ситуации се налага изследването на две извадки, но на сдвоени измервания\index{тест на две сдвоени извадки}. Това е ситуация при която всяко отделно измерване се отнася до два взаимно свързани субекта (примерно близнаци третирани с определен медикамент или измерване на бащи и синове). В такива ситуации трябва да се прилага сдвоен тест и това в пакета R се постига чрез флаг $paired=TRUE$ на функцията $t.test$. За илюстриране на работата със сдвоени данни може да се използва тестовото множество от данни за височините на бащите и синовете (Листинг \ref{listing0172}).

\begin{lstlisting}[caption=Т-тест на сдвоени данни, label=listing0172]
library( UsingR )

head( father.son )

#    fheight  sheight
# 1 65.04851 59.77827
# 2 63.25094 63.21404
# 3 64.95532 63.34242
# 4 65.75250 62.79238
# 5 61.13723 64.28113
# 6 63.02254 64.24221

t.test(father.son$sheight, father.son$fheight, paired=TRUE)

# 	Paired t-test
# 
# data:  father.son$sheight and father.son$fheight
# t = 11.789, df = 1077, p-value < 2.2e-16
# alternative hypothesis: true difference in means is not equal to 0
# 95 percent confidence interval:
#  0.8310296 1.1629160
# sample estimates:
# mean of the differences 
#               0.9969728 

# Visualization of the means.
ggplot(father.son,aes(x=fheight-sheight))+geom_density()+geom_vline(xintercept=mean(father.son$fheight-father.son$sheight))+geom_vline(xintercept=mean(father.son$fheight-father.son$sheight)+2*c(-1, 1)*sd(father.son$fheight-father.son$sheight)/sqrt(nrow(father.son)),linetype=2)
\end{lstlisting}

Ръстът на човека е установено, че е нормално разпределена, така че не е нужно да се прави проверка за нормалност и идентичност на дисперсиите на данните преди да се приложи $t$-тестът. 

\begin{figure}[h!]
  \centering
  \includegraphics[width=1.0\linewidth]{pic0058}
  \caption{Визуализация на средните при сдвоения тест}
\label{figure0058}
\end{figure}
\FloatBarrier

При настоящият пример тестът показва, че нулевата хипотеза\index{нулева хипотеза} трябва да бъде отхвърлена и трябва да се приеме, че поне за тази извадка от данни бащите и синовете имат различна височина (Фиг. \ref{figure0058}). 

\subsection{Дисперсионен анализ}

Логичното развитие след сравняването на две групи от данни е сравняването на много групи от данни. Най-разпространеният начин за такова сравнение е ANOVA\index{ANOVA} (analysis of variance)\index{дисперсионен анализ}, който се описва с Формула \ref{equation0012}.

\begin{equation}
F = \frac{ \sum_{i}^{}n_i(\bar{Y_i}-\bar{Y})^2 / (K-1) }{ \sum_{ij}^{}(Y_{ij}-\bar{Y_i})^2 / (N-K) }
\label{equation0012}
\end{equation}
\listofequations{F-статистика за ANOVA}

Където $n_i$ е броят наблюдения в група $i$, $\bar{Y_i}$ е средната стойност на група $i$, $\bar{Y}$ е общата средна, $Y_{ij}$ е $j$ наблюдение в група $i$, $N$ е общият брой наблюдения и $K$ е броят на изследваните групи. 

\begin{lstlisting}[caption=ANOVA тест, label=listing0173]
library( plyr )
library( reshape2 )

aov(tip~day-1, tips)

# Call:
#    aov(formula = tip ~ day - 1, data = tips)
# 
# Terms:
#                       day Residuals
# Sum of Squares  2203.0066  455.6866
# Deg. of Freedom         4       240
# 
# Residual standard error: 1.377931
# Estimated effects are balanced

aov(tip~day-1,tips)$coefficients

#   dayFri   daySat   daySun  dayThur 
# 2.734737 2.993103 3.255132 2.771452 

summary( aov(tip~day-1,tips) )

#            Df Sum Sq Mean Sq F value Pr(>F)    
# day         4 2203.0   550.8   290.1 <2e-16 ***
# Residuals 240  455.7     1.9                   
# ---
# Signif. Codes:  0  ***  0.001  **  0.01  *  0.05  .  0.1     1

ddply(tips, "day", plyr::summarize, tip.mean=mean(tip), tip.sd=sd(tip), Length=NROW(tip), tfrac=qt(p=.90, df=Length-1), Lower=tip.mean - tfrac*tip.sd/sqrt(Length), Upper=tip.mean + tfrac*tip.sd/sqrt(Length))

#    day tip.mean   tip.sd Length    tfrac    Lower    Upper
# 1  Fri 2.734737 1.019577     19 1.330391 2.423549 3.045925
# 2  Sat 2.993103 1.631014     87 1.291473 2.767272 3.218934
# 3  Sun 3.255132 1.234880     76 1.292941 3.071986 3.438277
# 4 Thur 2.771452 1.240223     62 1.295585 2.567386 2.975517

summary( lm(tip~day-1,data=tips) )

# Call:
# lm(formula = tip ~ day - 1, data = tips)
# 
# Residuals:
#     Min      1Q  Median      3Q     Max 
# -2.2451 -0.9931 -0.2347  0.5382  7.0069 
# 
# Coefficients:
#         Estimate Std. Error t value Pr(>|t|)    
# dayFri    2.7347     0.3161   8.651 7.46e-16 ***
# daySat    2.9931     0.1477  20.261  < 2e-16 ***
# daySun    3.2551     0.1581  20.594  < 2e-16 ***
# dayThur   2.7715     0.1750  15.837  < 2e-16 ***
# ---
# Signif. Codes:  0  ***  0.001  **  0.01  *  0.05  .  0.1     1
# 
# Residual standard error: 1.378 on 240 degrees of freedom
# Multiple R-squared:  0.8286,	Adjusted R-squared:  0.8257 
# F-statistic: 290.1 on 4 and 240 DF,  p-value: < 2.2e-16
\end{lstlisting}

В програмния пакет R функцията $aov$ служи за изчислението на ANOVA теста (Листинг \ref{listing0173}). Функцията използва синтаксиса за запис на формули, като от лявата страна стои анализираната променлива, а от дясната страна стои променливата използвана за групиране. 

За илюстриране на възможностите при анализа на дисперсиите данните от множеството за бакшиши може да се разделят в четири групи, според различните дни в които ресторантът работи. Наличието на минус единица в дясната страна на формулата оказва, че няма да се изчислява параметър за отрез. 

ANOVA тестът показва дали има значимо различие в някоя от групите, но не показва коя от групите води до това различие. За да бъде установена тази разлика може да се изчисли $p$-стойността. Резултатите от ANOVA теста могат да се потвърдят с множество $t$ тестове на отделните променливи групирани по двойки. 

Алтернатива на ANOVA тестът може да бъде линейна регресия една определяща променлива и без изчисление на срез. 

\section{Линейна регресия}

Един от най-използваните инструменти в статистическия анализ е линейната регресия\index{линейна регресия}. В най-простия си вариант тя се използва за определяне на взаимовръзката между две случайни променливи. Това означава, че ако се знае стойността на едната променлива с помощта на линейната регресия може да се предполага каква би била очакваната стойност на другата променлива. Прогнозираната променлива се нарича „отговор“, а променливата която служи за показател „предиктор“. 

\begin{equation}
y = ax + b + \epsilon
\label{equation0013}
\end{equation}
\listofequations{Уравнение на права}

Основната идея при простата линейна регресия е, че прогнозираната стойност е в линейна функционална зависимост от стойността на предиктора (Формула \ref{equation0013}). Където $\epsilon$ има смисъла на нормално разпределена грешка със средна стойност 0.

\begin{equation}
\label{equation0014}
a = \frac{ \sum_{i=1}^{n}(x_i-\bar{x})(y_i-\bar{y}) }{ \sum_{i=1}^{n}(x_i-\bar{x})^2 }
\end{equation}
\listofequations{Наклон на права}

Коефициентът $а$ има смисъла на наклон на правата и се изчислява по Формула \ref{equation0014}.

\begin{equation}
b = \bar{y} - a
\label{equation0015}
\end{equation}
\listofequations{Срез на права}

Коефициентът $b$ има смисъла на срез на правата по оста $y$ за стойност 0 по оста $x$ и се изчислява по Формула \ref{equation0015}. 

\begin{lstlisting}[caption=Линейна регресия, label=listing0174]
library(ggplot2)
library(UsingR)

head(father.son)

#    fheight  sheight
# 1 65.04851 59.77827
# 2 63.25094 63.21404
# 3 64.95532 63.34242
# 4 65.75250 62.79238
# 5 61.13723 64.28113
# 6 63.02254 64.24221

ggplot(father.son, aes(x=fheight, y=sheight)) + geom_point() + geom_smooth(method="lm") + labs(x="Fathers", y="Sons")

lm(sheight~fheight, data=father.son)

# Call:
# lm(formula = sheight ~ fheight, data = father.son)
# 
# Coefficients:
# (Intercept)      fheight  
#     33.8866       0.5141  

summary( lm(sheight~fheight,data=father.son) )

# Call:
# lm(formula = sheight ~ fheight, data = father.son)
# 
# Residuals:
#     Min      1Q  Median      3Q     Max 
# -8.8772 -1.5144 -0.0079  1.6285  8.9685 
# 
# Coefficients:
#             Estimate Std. Error t value Pr(>|t|)    
# (Intercept) 33.88660    1.83235   18.49   <2e-16 ***
# fheight      0.51409    0.02705   19.01   <2e-16 ***
# ---
# Signif. Codes:  0  ***  0.001  **  0.01  *  0.05  .  0.1     1
# 
# Residual standard error: 2.437 on 1076 degrees of freedom
# Multiple R-squared:  0.2513,	Adjusted R-squared:  0.2506 
# F-statistic: 361.2 on 1 and 1076 DF,  p-value: < 2.2e-16
\end{lstlisting}

За демонстрация на линейна регресия е удачно да се използва множеството данни за височината на бащите и синовете (Листинг \ref{listing0174}). Височината на бащата се използва като предиктор, а височината на сина като отговор (Фиг. \ref{figure0059}).

\begin{figure}[h!]
  \centering
  \includegraphics[width=1.0\linewidth]{pic0059}
  \caption{Линейна регресия бащи-синове}
\label{figure0059}
\end{figure}
\FloatBarrier

Синята линия, която преминава през точките е правата изчислена по формулите за линейна регресия. Сивият регион около синята линия показва нивото на доверие, което може да се припише на прогнозата. Изобразяването на данните дава представа за възможностите на линейната регресия, но не показва самото изчисляване на коефициентите. 

В програмния пакет R изчисляването на тези коефициенти става с функцията $lm$. За пореден път е видно приложението на записа от тип формула. От лявата страна е променливата отговори, а от дясната страна променливата предиктор. В резултат от пресмятането се изчислява наклона на правата и среза с ординатната ос. Изчислението на двата параметъра за линейна регресия нямат особено голям смисъл, ако не се отчете стандартната грешка. Тя дава оценка за достоверността на прогнозите. Обобщената информация получена с функцията $summary$ включва стандартната грешка, $t$-статистика, $p$-стойности на коефициентите, степени на свобода и $F$-статистика.

\section*{Заключение}

Без значение дали трябва да се пресметнат описателни статистики или да се направи сравнителен анализ, програмният пакет R разполага с пълен набор от функции за извършването на тези изчисления. Най-популярните пресмятания за за средна стойност, медиана, стандартно отклонение, корелация, ковариация, дисперсионен анализ, тест на Стюдънт и линейна регресия. 

